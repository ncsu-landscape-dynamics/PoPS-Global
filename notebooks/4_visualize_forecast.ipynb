{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Forecast Result\n",
    "\n",
    "Use this notebook to generate maps and plots to visualize the aggregated forecast results. \n",
    "\n",
    "This notebook can be run after 0, 1, 2, 3a (optional), 3b, and 3c.\n",
    "\n",
    "All plots are shown in the notebook, and saved as .PNG to the results folder. There are many plot options given here. You can run all of them and select only those of interest to use, or selectively run specific plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up workspace from env and configuration files \n",
    "\n",
    "First, import needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import dotenv\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to main repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate one level up to the main repository\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in path variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read environmental variables\n",
    "env_file = os.path.join('.env') \n",
    "dotenv.load_dotenv(env_file)\n",
    "\n",
    "input_dir = os.getenv('INPUT_PATH')\n",
    "out_dir = os.getenv('OUTPUT_PATH')\n",
    "countries_path = os.getenv('COUNTRIES_PATH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in parameters from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the path to the forecasted model outputs\n",
    "with open(\"config.json\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "sim_name = config['sim_name']\n",
    "run_name = f\"{sim_name}_forecast\"\n",
    "\n",
    "results_dir = f\"{out_dir}/{run_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directories for additional summary statistics and visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = r\"Q:\\Shared drives\\Pandemic Data\\slf_model\\outputs\\slf_ensemble_calibrated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{out_dir}/summary_stats/{run_name}/\"):\n",
    "    os.makedirs(f\"{out_dir}/summary_stats/{run_name}/\")\n",
    "\n",
    "if not os.path.exists(f\"{results_dir}/figs/\"):\n",
    "    os.makedirs(f\"{results_dir}/figs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native countries list\n",
    "native_countries_list = config[\"native_countries_list\"]\n",
    "\n",
    "# Country of interest\n",
    "coi_ISO3 = config[\"coi\"]\n",
    "\n",
    "# Run years\n",
    "start_year = config[\"start_year\"]\n",
    "end_year = config[\"stop_year\"]\n",
    "sim_years = config[\"sim_years\"]\n",
    "num_runs = config[\"run_count\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the country file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read country file\n",
    "\n",
    "countries_geo = geopandas.read_file(countries_path)\n",
    "countries = countries_geo.iloc[:,[4]]\n",
    "countries.set_index(\"NAME\")\n",
    "countries_firstintro = countries.iloc[:,[0]]\n",
    "countries_reintros = countries.iloc[:,[0]]\n",
    "org_dest_all = pd.DataFrame()\n",
    "\n",
    "# Extract full name of COI\n",
    "coi = countries_geo.loc[countries_geo[\"ISO3\"]==coi_ISO3,\"NAME\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and aggregate model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open all model outputs from individual runs, and read aggregate first introductions and re-introductions.\n",
    "\n",
    "Note: Once you've gone through this step once, you can skip ahead and read in the aggregated data from .csv to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob(f'{results_dir}/*/*/origin_destination.csv')\n",
    "\n",
    "org_dest_all = pd.DataFrame()\n",
    "first_intros_all = pd.DataFrame()\n",
    "first_exports_all = pd.DataFrame()\n",
    "country_count = (pd.DataFrame(index=countries.iloc[:,0], columns=[\"count\"])).fillna(0)\n",
    "coi_first_intros_by_origin = pd.DataFrame()\n",
    "\n",
    "for sample, path in enumerate(paths):\n",
    "    path_in_str = str(path)\n",
    "    org_dest = (pd.read_csv(path)).iloc[:,1:4]\n",
    "    org_dest[\"TS\"] = org_dest[\"TS\"].astype(str)\n",
    "    org_dest[\"TS\"] = org_dest.TS.str[:4].astype(int)\n",
    "    org_dest_all = org_dest_all.append(org_dest)\n",
    "    \n",
    "    intros = org_dest.iloc[:,1:4]\n",
    "    intros = intros.rename(columns={\"Destination\":\"NAME\", \"TS\":sample})\n",
    "    firstintro = intros.drop_duplicates(subset = [\"NAME\"])\n",
    "    countries_firstintro = pd.merge(countries_firstintro, firstintro, on=\"NAME\", how=\"left\")\n",
    "    reintros = intros.groupby(\"NAME\").count()\n",
    "    countries_reintros = pd.merge(countries_reintros, reintros, on=\"NAME\", how=\"left\")\n",
    "\n",
    "    # get list of countries in transmission network and add to count\n",
    "    run_countries = list(set(list(org_dest.Origin) + list(org_dest.Destination)))\n",
    "    for country in run_countries:\n",
    "        country_count.loc[country] = country_count.loc[country] + 1\n",
    "\n",
    "    # identify first introductions to each country\n",
    "    first_intro = org_dest.drop_duplicates(subset = [\"Destination\"])\n",
    "    first_intros_all = first_intros_all.append(first_intro, ignore_index=True)\n",
    "\n",
    "    # identify first export from each country\n",
    "    first_export = org_dest.drop_duplicates(subset = [\"Origin\"])\n",
    "    first_exports_all = first_exports_all.append(first_export, ignore_index=True)\n",
    "\n",
    "    # COI first intros by origin\n",
    "    coi_first_intros = (org_dest[org_dest[\"Destination\"] == coi]).drop_duplicates(subset = [\"Origin\"])\n",
    "    coi_first_intros_by_origin = coi_first_intros_by_origin.append(coi_first_intros, ignore_index=True)\n",
    "\n",
    "\n",
    "countries_firstintro = countries_firstintro.set_index(\"NAME\")\n",
    "countries_reintros = countries_reintros.set_index(\"NAME\")\n",
    "\n",
    "# Save all summaries    \n",
    "    \n",
    "org_dest_all.to_csv(f\"{out_dir}/summary_stats/{run_name}/org_dest_all.csv\", index=False)\n",
    "country_count.reset_index().to_csv(f\"{out_dir}/summary_stats/{run_name}/country_count.csv\", index=False)\n",
    "first_intros_all.to_csv(f\"{out_dir}/summary_stats/{run_name}/first_intros_all.csv\", index=False)\n",
    "first_exports_all.to_csv(f\"{out_dir}/summary_stats/{run_name}/first_exports_all.csv\", index=False)\n",
    "coi_first_intros_by_origin.to_csv(f\"{out_dir}/summary_stats/{run_name}/coi_first_intros_by_origin.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a separate dataframe from the perspective of the \"country of interest\" (coi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coi_intros = first_intros_all[first_intros_all[\"Destination\"] == coi]\n",
    "coi_intros = coi_intros.groupby(\"Origin\").count()[[\"Destination\"]]\n",
    "coi_intros = coi_intros.rename(columns={\"Destination\":\"COI source\"})\n",
    "\n",
    "countries_geo = countries_geo.merge(coi_intros, how=\"left\", left_on=\"NAME\", right_on=\"Origin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture statistical moments of the introduction year distribution: mean, mode, min, max, and range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_yr_mean_all = []\n",
    "arr_yr_mode_all = []\n",
    "arr_yr_min_all = []\n",
    "arr_yr_max_all = []\n",
    "arr_yr_range_all = []\n",
    "intro_proportion_all = []\n",
    "for row in range(len(countries_firstintro.index)):\n",
    "    runs_no_intro = countries_firstintro.iloc[row].isnull().sum()\n",
    "    intro_proportion = 1 - (runs_no_intro / len(countries_firstintro.columns))\n",
    "    intro_proportion_all.append(intro_proportion)\n",
    "    if intro_proportion == 0:\n",
    "        arr_yr_min_all.append(None)\n",
    "        arr_yr_max_all.append(None)\n",
    "        arr_yr_mean_all.append(None)\n",
    "        arr_yr_mode_all.append(None)\n",
    "        arr_yr_range_all.append(None)\n",
    "        \n",
    "    else:\n",
    "        arr_yr_min = countries_firstintro.iloc[row].min()\n",
    "        arr_yr_min_all.append(arr_yr_min)\n",
    "        arr_yr_max = countries_firstintro.iloc[row].max()\n",
    "        arr_yr_max_all.append(arr_yr_max)\n",
    "        arr_yr_mean = math.floor(np.nanmean(countries_firstintro.iloc[row]))\n",
    "        arr_yr_mean_all.append(arr_yr_mean)\n",
    "        arr_yr_mode = countries_firstintro.iloc[row].mode()\n",
    "        if len(arr_yr_mode) > 1:\n",
    "            arr_yr_mode = int(arr_yr_mode.mean())\n",
    "        else:\n",
    "            arr_yr_mode = arr_yr_mode[0]\n",
    "        arr_yr_mode_all.append(arr_yr_mode)\n",
    "        arr_yr_range_all.append(arr_yr_max - arr_yr_min)\n",
    "\n",
    "countries_firstintro[\"arr_yr_mean\"] = arr_yr_mean_all\n",
    "countries_firstintro[\"arr_yr_mode\"] = arr_yr_mode_all\n",
    "countries_firstintro[\"arr_yr_min\"] = arr_yr_min_all\n",
    "countries_firstintro[\"arr_yr_max\"] = arr_yr_max_all\n",
    "countries_firstintro[\"arr_yr_range\"] = arr_yr_range_all\n",
    "countries_firstintro[\"intro_proportion\"] = intro_proportion_all\n",
    "countries_firstintro.loc[native_countries_list, 'arr_yr_mean'] = None\n",
    "countries_firstintro.loc[native_countries_list, 'arr_yr_mode'] = None\n",
    "countries_firstintro.loc[native_countries_list, 'arr_yr_min'] = None\n",
    "countries_firstintro.loc[native_countries_list, 'arr_yr_max'] = None\n",
    "countries_firstintro.loc[native_countries_list, 'arr_yr_range'] = None\n",
    "countries_firstintro.loc[native_countries_list, 'intro_proportion'] = None\n",
    "\n",
    "countries_reintros = countries_reintros.fillna(0)\n",
    "countries_reintros[\"num_reintros_mean\"] = round(countries_reintros.mean(axis=1)).astype(int)\n",
    "countries_reintros.at[native_countries_list, 'num_reintros_mean'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_geo = countries_geo.merge(countries_firstintro[\"arr_yr_mean\"], on='NAME')\n",
    "countries_geo[\"arr_yr_mean\"] = countries_geo[\"arr_yr_mean\"].astype(\"Int64\")\n",
    "\n",
    "countries_geo = countries_geo.merge(countries_firstintro[\"arr_yr_mode\"], on='NAME')\n",
    "countries_geo[\"arr_yr_mode\"] = countries_geo[\"arr_yr_mode\"].astype(\"Int64\")\n",
    "\n",
    "countries_geo = countries_geo.merge(countries_firstintro[\"arr_yr_min\"], on='NAME')\n",
    "countries_geo[\"arr_yr_min\"] = countries_geo[\"arr_yr_min\"].astype(\"Int64\")\n",
    "\n",
    "countries_geo = countries_geo.merge(countries_firstintro[\"arr_yr_max\"], on='NAME')\n",
    "countries_geo[\"arr_yr_max\"] = countries_geo[\"arr_yr_max\"].astype(\"Int64\")\n",
    "\n",
    "countries_geo = countries_geo.merge(countries_firstintro[\"arr_yr_range\"], on='NAME')\n",
    "\n",
    "countries_geo = countries_geo.merge(countries_firstintro[\"intro_proportion\"], on='NAME')\n",
    "\n",
    "countries_geo = countries_geo.merge(countries_reintros[\"num_reintros_mean\"], on='NAME')\n",
    "\n",
    "# Save summary geo to file\n",
    "\n",
    "countries_geo.to_file(f\"{out_dir}/summary_stats/{run_name}/country_intos.gpkg\", index=False, driver=\"GPKG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option: Read in aggregated outputs\n",
    "If you've already gone through the steps above, you can start from here and read in the aggregated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_geo = geopandas.read_file(f\"{out_dir}/summary_stats/{run_name}/country_intos.gpkg\")\n",
    "\n",
    "org_dest_all = pd.read_csv(f\"{out_dir}/summary_stats/{run_name}/org_dest_all.csv\")\n",
    "country_count = pd.read_csv(f\"{out_dir}/summary_stats/{run_name}/country_count.csv\")\n",
    "first_intros_all = pd.read_csv(f\"{out_dir}/summary_stats/{run_name}/first_intros_all.csv\")\n",
    "first_exports_all = pd.read_csv(f\"{out_dir}/summary_stats/{run_name}/first_exports_all.csv\")\n",
    "coi_first_intros_by_origin = pd.read_csv(f\"{out_dir}/summary_stats/{run_name}/coi_first_intros_by_origin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plots: maps and other figures\n",
    "\n",
    "### Maps: \n",
    "\n",
    "What was the proportion of runs with introductions, for each country? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "ax.set_title(\"Proportion of Runs with Introductions\\n\" + run_name, fontsize=18)\n",
    "countries_geo.plot(column='intro_proportion', ax=ax, legend=True, legend_kwds={'label': \"proportion\"}, missing_kwds={'color': 'lightgrey'}, cax=cax)\n",
    "plt.savefig(results_dir + \"/figs/intro_proportion.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What countries were introduction sources to the Country of Interest? How many total introductions were there from each, across runs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "ax.set_title(\"Introduction Sources for \" + coi + \"\\n\" + run_name, fontsize=18)\n",
    "countries_geo.plot(column='COI source', ax=ax, legend=True, legend_kwds={'label': \"intro source count\"}, missing_kwds={'color': 'lightgrey'}, cax=cax)\n",
    "plt.savefig(results_dir + \"/figs/\" + coi + \"_intro_sources.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the mean number of re-introductions to each country, cross runs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "ax.set_title(\"Number of Reintroductions (mean)\\n\" + run_name, fontsize=18)\n",
    "countries_geo.plot(column='num_reintros_mean', ax=ax, legend=True, legend_kwds={'label': \"reintroductions\"}, missing_kwds={'color': 'lightgrey'}, cax=cax)\n",
    "plt.savefig(results_dir + \"/figs/num_reintros.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next several plots present the mean, min, max, and range of years of first introduction to each country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.title(\"Year of First Introduction (mean)\\n\" + run_name, fontsize=18)\n",
    "countries_geo.plot(column='arr_yr_mean', categorical=True, cmap=\"viridis\", legend=True, ax=ax, missing_kwds={'color': 'lightgrey'}, legend_kwds={'loc': 'lower left'})\n",
    "#countries_geo.plot(column='arr_yr_mode', scheme=\"User_Defined\", classification_kwds=dict(bins=[2010,2012,2014,2016,2018,2020]), legend=True, ax=ax, missing_kwds={'color': 'lightgrey'})\n",
    "plt.savefig(results_dir + \"/figs/first_intros_mean.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.title(\"Year of First Introduction (min)\\n\" + run_name, fontsize=18)\n",
    "countries_geo.plot(column='arr_yr_min', categorical=True, cmap=\"viridis\", legend=True, ax=ax, missing_kwds={'color': 'lightgrey'}, legend_kwds={'loc': 'lower left'})\n",
    "#countries_geo.plot(column='arr_yr_mode', scheme=\"User_Defined\", classification_kwds=dict(bins=[2010,2012,2014,2016,2018,2020]), legend=True, ax=ax, missing_kwds={'color': 'lightgrey'})\n",
    "plt.savefig(results_dir + \"/figs/first_intros_min.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.title(\"Year of First Introduction (max)\\n\" + run_name, fontsize=18)\n",
    "countries_geo.plot(column='arr_yr_max', categorical=True, cmap=\"viridis\", legend=True, ax=ax, missing_kwds={'color': 'lightgrey'}, legend_kwds={'loc': 'lower left'})\n",
    "#countries_geo.plot(column='arr_yr_mode', scheme=\"User_Defined\", classification_kwds=dict(bins=[2010,2012,2014,2016,2018,2020]), legend=True, ax=ax, missing_kwds={'color': 'lightgrey'})\n",
    "plt.savefig(results_dir + \"/figs/first_intros_max.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.title(\"Year of First Introduction (range)\\n\" + run_name, fontsize=18)\n",
    "countries_geo.plot(column='arr_yr_range', categorical=True, cmap=\"viridis\", legend=True, ax=ax, missing_kwds={'color': 'lightgrey'}, legend_kwds={'loc': 'lower left'})\n",
    "#countries_geo.plot(column='arr_yr_mode', scheme=\"User_Defined\", classification_kwds=dict(bins=[2010,2012,2014,2016,2018,2020]), legend=True, ax=ax, missing_kwds={'color': 'lightgrey'})\n",
    "plt.savefig(results_dir + \"/figs/first_intros_range.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two plots limit the visualizations to only include countries that received introductions in over 50% of the model runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "ax.set_title(\"Portion of Runs with Introductions (>50%)\\n\" + run_name, fontsize=18)\n",
    "countries_geo['intro_proportion'] = np.where(countries_geo['intro_proportion'] < 0.5, np.nan, countries_geo['intro_proportion'])\n",
    "countries_geo.plot(column='intro_proportion', ax=ax, legend=True, legend_kwds={'label': \"proportion\"}, missing_kwds={'color': 'lightgrey'}, cax=cax)\n",
    "plt.savefig(results_dir + \"/figs/intro_proportion_more50pct.png\", bbox_inches='tight', pad_inches = 0.01)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(20, 20))\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"2%\", pad=0.1)\n",
    "ax.set_title(\"Mean Year of First Introduction (mean of runs with intros >50%)\\n\" + run_name, fontsize=18)\n",
    "countries_geo['arr_yr_mean'] = np.where(countries_geo['intro_proportion'] < 0.5, np.nan, countries_geo['arr_yr_mean'])\n",
    "countries_geo.plot(column='arr_yr_mean', categorical=True, cmap=\"viridis\", legend=True, ax=ax, missing_kwds={'color': 'lightgrey'}, legend_kwds={'loc': 'lower left'})\n",
    "plt.savefig(results_dir + \"/figs/first_intro_mean_more50pct.png\", bbox_inches='tight', pad_inches = 0.01)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional plots: histograms and heatmap of introductions by country source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess bridgehead populations with a temporal heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations_all = list(set(first_intros_all[\"Destination\"]))\n",
    "min_intro_prop = 0.5\n",
    "destinations = []\n",
    "for i in range(len(destinations_all)):\n",
    "    if len(first_intros_all.loc[first_intros_all[\"Destination\"] == destinations_all[i]]) > num_runs * min_intro_prop:\n",
    "        destinations.append(destinations_all[i])\n",
    "num_destinations = len(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count origins for each timestep\n",
    "origin_countries_by_ts = (pd.DataFrame(index=countries.iloc[:,0], columns=sim_years)).fillna(0)\n",
    "origins = (org_dest_all.groupby([\"Origin\", \"TS\"]).count()).reset_index().fillna(0)\n",
    "for i in range(len(origins)):\n",
    "    origin = origins.iloc[i,:]\n",
    "    origin_countries_by_ts.loc[origin.Origin, origin.TS] = origin.Destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of bridgehead introductions\n",
    "origin_countries_by_ts_filtered = origin_countries_by_ts[origin_countries_by_ts.loc[:,2029] > 0]\n",
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "plt.subplots_adjust(left=0.22, right=1, top = .92)\n",
    "res = sns.heatmap(origin_countries_by_ts_filtered.drop(native_countries_list, errors=\"ignore\"), cmap = sns.color_palette(\"light:#31688e\", as_cmap=True), linewidths = 0.30, annot = False, cbar_kws={'label':f'Total Outgoing Transmissions Over {num_runs} Model Runs'})\n",
    "res.set_xticklabels(res.get_xmajorticklabels(), fontsize = 14)\n",
    "res.set_yticklabels(res.get_ymajorticklabels(), fontsize = 14)\n",
    "ax.figure.axes[-1].yaxis.label.set_size(14)\n",
    "plt.title(\"Exports from Bridgehead Populations\", fontsize=20, pad=15)\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"Year\", fontsize = 14)\n",
    "plt.savefig(f\"{results_dir}/figs/bridgehead_sources.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms of introductions by year, for individual countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of first intros by destination\n",
    "fig, axs = plt.subplots(2, math.ceil(num_destinations/2), sharey=True, sharex=True, figsize=(12,6))\n",
    "fig.subplots_adjust(hspace=0.35, wspace=0.15, top=0.82)\n",
    "fig.text(0.5, 0.04, 'year', ha='center', fontsize=16)\n",
    "fig.text(0.08, 0.5, 'model runs', va='center', rotation='vertical', fontsize=18)\n",
    "axs = axs.ravel()\n",
    "for i in range(num_destinations):\n",
    "    axs[i].hist(list(first_intros_all.loc[first_intros_all[\"Destination\"] == destinations[i], \"TS\"]))\n",
    "    axs[i].set_title(destinations[i])\n",
    "plt.suptitle(f'''{run_name} \\n Year of First Introduction by Destination''', fontsize=18)\n",
    "plt.savefig(f'{results_dir}/figs/first_intro_by_destination.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write plots for each country to file only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save separate plots for histograms of first intros by destination\n",
    "for i in range(num_destinations):\n",
    "    fig, ax = plt.subplots(1, figsize=(4, 3))\n",
    "    fig.subplots_adjust(left=0.27, top=0.76, bottom=0.21)\n",
    "    ax.hist(list(first_intros_all.loc[first_intros_all[\"Destination\"] == destinations[i], \"TS\"]), color=\"#31688e\")\n",
    "    ax.set_title(f'''{destinations[i]}\\nFirst Introduction Year''', fontsize=18, pad=14)\n",
    "    ax.set_xlabel(\"year\", fontsize=18)\n",
    "    ax.set_ylabel(\"% model runs\", fontsize=18)\n",
    "    ax.set_xlim(left=2005,right=2030)\n",
    "    ax.set_ylim(top=1000)\n",
    "    y_vals = ax.get_yticks()\n",
    "    ax.set_xticklabels([\"\",2010,\"\",2020,\"\",2030], fontsize=16)\n",
    "    ax.set_yticklabels(['{:3.0f}%'.format((x / 1000) * 100) for x in y_vals], fontsize=16)\n",
    "    plt.savefig(f'{results_dir}/figs/{destinations[i]}_first_intros.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All introductions by country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations_all = list(set(org_dest_all[\"Destination\"]))\n",
    "min_intro_prop = 0.5\n",
    "destinations = []\n",
    "for i in range(len(destinations_all)):\n",
    "    if len(org_dest_all.loc[org_dest_all[\"Destination\"] == destinations_all[i]]) > num_runs * min_intro_prop:\n",
    "        destinations.append(destinations_all[i])\n",
    "num_destinations = len(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of all intros by destination\n",
    "fig, axs = plt.subplots(2, math.ceil(num_destinations/2), sharey=True, sharex=True, figsize=(12,6))\n",
    "fig.subplots_adjust(hspace=0.35, wspace=0.15, top=0.82)\n",
    "fig.text(0.5, 0.04, 'year', ha='center', fontsize=13)\n",
    "fig.text(0.08, 0.5, 'model runs', va='center', rotation='vertical', fontsize=18)\n",
    "axs = axs.ravel()\n",
    "for i in range(num_destinations):\n",
    "    axs[i].hist(list(org_dest_all.loc[org_dest_all[\"Destination\"] == destinations[i], \"TS\"]))\n",
    "    axs[i].set_title(destinations[i])\n",
    "plt.suptitle(f'''{run_name} \\n Introductions by Destination''', fontsize=18)\n",
    "plt.savefig(f'{results_dir}/figs/all_intros_by_destination.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save individual histograms to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save separate plots for histograms of all intros by destination\n",
    "for i in range(num_destinations):\n",
    "    fig, ax = plt.subplots(1, figsize=(4,3))\n",
    "    fig.subplots_adjust(left=0.22, top=0.78, bottom=0.2)\n",
    "    ax.hist(list(org_dest_all.loc[org_dest_all[\"Destination\"] == destinations[i], \"TS\"]), color=\"#31688e\")\n",
    "    ax.set_title(f'''{destinations[i]}\\nIntroduction Year''', fontsize=18, pad=14)\n",
    "    ax.set_xlabel(\"year\", fontsize=18)\n",
    "    ax.set_ylabel(\"% model runs\", fontsize=18)\n",
    "    ax.set_xlim(left=2005,right=2030)\n",
    "    ax.set_ylim(top=1000)\n",
    "    y_vals = ax.get_yticks()\n",
    "    ax.set_xticklabels([\"\",2010,\"\",2020,\"\",2030], fontsize=16)\n",
    "    ax.set_yticklabels(['{:3.0f}%'.format((x / 1000) * 100) for x in y_vals], fontsize=16)\n",
    "    plt.savefig(f'{results_dir}/figs//{destinations[i]}_all_intros.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction summaries for the country of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10th Percentile\n",
    "def q10(x):\n",
    "    return x.quantile(0.1)\n",
    "\n",
    "coi_all_intros = org_dest_all[org_dest_all[\"Destination\"] == coi]\n",
    "\n",
    "# Save COI intros summaries\n",
    "coi_all_intros_by_origin_summary = coi_all_intros.groupby([\"Origin\"]).agg({'TS': ['count', q10, 'min', 'mean', 'median', 'max', 'std']})\n",
    "coi_all_intros_by_origin_summary.to_csv(f'{out_dir}/summary_stats/{run_name}/all_intros_by_source_to_{coi}.csv')\n",
    "coi_first_intros_by_origin_summary = coi_first_intros_by_origin.groupby([\"Origin\"]).agg({'TS': ['count', 'min', q10, 'mean', 'median', 'max', 'std']})\n",
    "coi_first_intros_by_origin_summary.to_csv(f'{out_dir}/summary_stats/{run_name}/first_intro_by_source_to_{coi}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save individual country histograms to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save separate plots for histograms of all COI first intros by origin\n",
    "coi_origins = list(set(coi_first_intros_by_origin.Origin))\n",
    "for i in range(len(coi_origins)):\n",
    "    fig, ax = plt.subplots(1, figsize=(4,3))\n",
    "    fig.subplots_adjust(left=0.25, top=0.75, bottom=0.21, right=0.85)\n",
    "    ax.hist(list(coi_first_intros_by_origin.loc[coi_first_intros_by_origin[\"Origin\"] == coi_origins[i], \"TS\"]), color=\"#31688e\")\n",
    "    q10_value = q10(coi_first_intros_by_origin.loc[coi_first_intros_by_origin[\"Origin\"] == coi_origins[i], \"TS\"])\n",
    "    ax.axvline(q10_value, color=\"red\")\n",
    "    plt.text(q10_value - 2.2,17.5,round(q10_value),rotation=90, fontsize=15)\n",
    "    ax.set_title(f'''{coi_origins[i]}\\nFirst Export to {coi}''', fontsize=18, pad=18)\n",
    "    ax.set_xlabel(\"year\", fontsize=18)\n",
    "    ax.set_ylabel(\"% model runs\", fontsize=18)\n",
    "    ax.set_xlim(left=2005,right=2030)\n",
    "    ax.set_ylim(top=25)\n",
    "    y_vals = ax.get_yticks()\n",
    "    ax.set_xticklabels([\"\",2010,\"\",2020,\"\",2030], fontsize=16)\n",
    "    ax.set_yticklabels(['{:3.1f}%'.format((x / 1000) * 100) for x in y_vals], fontsize=16)\n",
    "    plt.savefig(f'{results_dir}/figs/{coi_origins[i]}_first_intros_to_{coi}.png', dpi=300)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "948a6e006881c847639198d4e28507cd0955feff6e008072919ba7456f12f8bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('Pandemic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
