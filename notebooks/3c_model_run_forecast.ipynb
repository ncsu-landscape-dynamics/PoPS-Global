{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model run: Forecast \n",
    "Use this notebook to run and evaluate a parameter grid-search. \n",
    "\n",
    "This notebook can be run after 0, 1, 2, and 3b. We recommend also running 3a first, to check for and troubleshoot issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dotenv\n",
    "import os \n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandemic.multirun_helpers import write_commands, generate_param_samples\n",
    "# import summary stats run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables and paths from .env\n",
    "dotenv.load_dotenv('.env')\n",
    "\n",
    "# Read environmental variables\n",
    "input_dir = os.getenv('INPUT_PATH')\n",
    "out_dir = os.getenv('OUTPUT_PATH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the summary stats from the grid search to fit distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "sim_name = config['sim_name']\n",
    "\n",
    "run_name = f\"{sim_name}_calibrate\"\n",
    "total_runs = config[\"run_count\"] \n",
    "\n",
    "stats_dir = f\"{out_dir}/summary_stats/{run_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {\"start_max\":\"start\",\"alpha_max\":\"alpha\",\"beta_max\":\"beta\",\n",
    "    \"lamda_max\":\"lamda\",\"count_known_countries_time_window_fbeta_mean\":\"fbeta\"}\n",
    "\n",
    "agg_df = (\n",
    "    pd.read_csv(f\"{stats_dir}/summary_stats_bySample.csv\")\n",
    "    .rename(columns=col_dict)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring possible quantile thresholds for fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a % threshold (0 - 100) - adjust based on the below plots\n",
    "\n",
    "quant_threshold = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vals = []\n",
    "min_fbeta = []\n",
    "\n",
    "for val in range(70,100):\n",
    "    subset = agg_df.loc[agg_df['fbeta']>=agg_df['fbeta'].quantile(val/100)]\n",
    "    count_vals.append(len(subset.index))\n",
    "    min_fbeta.append(subset['fbeta'].min())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stats = pd.DataFrame(\n",
    "    {\"quantile\":range(70,100), \n",
    "    \"count\":count_vals, \n",
    "    \"min_fbeta\":min_fbeta}\n",
    "    ).set_index(\"quantile\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual: How many samples and what Fbeta scores are captured with each threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sample_stats[\"count\"].plot(ax = ax1)\n",
    "ax1.vlines(quant_threshold, ymin=sample_stats[\"count\"].min(), ymax=sample_stats[\"count\"].max(), linestyle='dashed', color=\"firebrick\")\n",
    "ax1.set_title(\"Count\")\n",
    "\n",
    "sample_stats[\"min_fbeta\"].plot(ax = ax2)\n",
    "ax2.vlines(quant_threshold, ymin=sample_stats[\"min_fbeta\"].min(), ymax=sample_stats[\"min_fbeta\"].max(), linestyle='dashed', color=\"firebrick\")\n",
    "ax2.set_title(\"Fbeta\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual: What do the distributions of alpha and lamda look like with that threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df['top']=np.where(agg_df['fbeta']>=agg_df['fbeta'].quantile(quant_threshold/100),'top','low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha by year\n",
    "\n",
    "ax = sns.relplot(x=\"alpha\",y=\"fbeta\", col=\"start\",hue=\"top\",palette=\"rocket\",data=agg_df,edgecolor=\"black\",linewidth=0.5,s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lamda by year\n",
    "\n",
    "ax = sns.relplot(x=\"lamda\",y=\"fbeta\", col=\"start\",hue=\"top\",palette=\"rocket\",data=agg_df,edgecolor=\"black\",linewidth=0.5,s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta by year\n",
    "\n",
    "ax = sns.relplot(x=\"beta\",y=\"fbeta\", col=\"start\",hue=\"top\",palette=\"rocket\",data=agg_df,edgecolor=\"black\",linewidth=0.5,s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top parameter distribution plot\n",
    "\n",
    "ax = sns.relplot(x=\"alpha\", y=\"lamda\", col=\"start\", hue=\"fbeta\", palette=\"mako_r\", data=agg_df.loc[agg_df['top']==\"top\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the multivariate normal distribution and sampled parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many distinct parameter samples do you want to generate?\n",
    "n_samples = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits a separate distribution per year \n",
    "\n",
    "samples_to_run = generate_param_samples(agg_df, n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sampled parameters to .csv as a backup/for later use\n",
    "\n",
    "samples_to_run.to_csv(f\"{stats_dir}/sampled_param_sets.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the parameter distributions that will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to visually examine the parameter posterior distributions\n",
    "\n",
    "ax = sns.jointplot(x=\"alpha\", y=\"lamda\", hue=\"start\", data=samples_to_run, palette=\"deep\", alpha = 0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out sampled parameters to runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_forecast = \"\"\n",
    "\n",
    "for index, row in samples_to_run.iterrows():\n",
    "    commands_forecast += write_commands(row, start_run = 0, end_run = 0, run_type = \"forecast\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you will run on HPC or later, write these to file \n",
    "\n",
    "# f1 = open(stats_dir + \"/commands.txt\", 'w')\n",
    "# f1.write(commands_forecast)\n",
    "# f1.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run forecast with sampled parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model here\n",
    "for command in commands_forecast.split('\\n'):\n",
    "    ! {command}\n",
    "\n",
    "# Write to outdir/run_name + _forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary stats\n",
    "\n",
    "# Update summary stats script:\n",
    "\n",
    "# If path ends in _forecast\n",
    "# Agg on run rather than sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review model summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step: Visualize forecast\n",
    "\n",
    "Use notebook 4 to visualize the results of your forecast simulation. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "948a6e006881c847639198d4e28507cd0955feff6e008072919ba7456f12f8bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('Pandemic': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
