{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model run: Forecast \n",
    "Use this notebook to run and evaluate a parameter grid-search. \n",
    "\n",
    "This notebook can be run after 0, 1, 2, and 3b. We recommend also running 3a first, to check for and troubleshoot issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up workspace from env and configuration files \n",
    "\n",
    "First, import needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dotenv\n",
    "import os \n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to main repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed PoPS Global functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandemic.multirun_helpers import write_commands, generate_param_samples\n",
    "# import summary stats run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in path variables from .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables and paths from .env\n",
    "dotenv.load_dotenv('.env')\n",
    "\n",
    "# Read environmental variables\n",
    "input_dir = os.getenv('INPUT_PATH')\n",
    "out_dir = os.getenv('OUTPUT_PATH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in parameters from config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "sim_name = config['sim_name']\n",
    "coi = config['coi']\n",
    "sim_years = config['sim_years']\n",
    "\n",
    "run_name = f\"{sim_name}_calibrate\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the summary stats from the grid search to generate a parameter distribution\n",
    "\n",
    "Read summary statistics from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dir = f\"{out_dir}/summary_stats/{run_name}\"\n",
    "\n",
    "col_dict = {\"start_max\":\"start\",\"alpha_max\":\"alpha\",\"beta_max\":\"beta\",\n",
    "    \"lamda_max\":\"lamda\",\"count_known_countries_time_window_fbeta_mean\":\"fbeta\"}\n",
    "\n",
    "agg_df = (\n",
    "    pd.read_csv(f\"{stats_dir}/summary_stats_bySample.csv\")\n",
    "    .rename(columns=col_dict)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set a performance threshold\n",
    "Select a threhold percentile value (on F-beta) to determine which samples to use to fit the distribution. \n",
    "\n",
    "The viusalizations below help explore the possible thresholds and their impact on the number of samples included and the \n",
    "corresponding cut-off value for F-beta, and on the distribution of parameters included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a % threshold (0 - 100) - adjust based on the below plots\n",
    "\n",
    "quant_threshold = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vals = []\n",
    "min_fbeta = []\n",
    "\n",
    "for val in range(70,100):\n",
    "    subset = agg_df.loc[agg_df['fbeta']>=agg_df['fbeta'].quantile(val/100)]\n",
    "    count_vals.append(len(subset.index))\n",
    "    min_fbeta.append(subset['fbeta'].min())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stats = pd.DataFrame(\n",
    "    {\"quantile\":range(70,100), \n",
    "    \"count\":count_vals, \n",
    "    \"min_fbeta\":min_fbeta}\n",
    "    ).set_index(\"quantile\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual: How many samples and what Fbeta scores are captured with each threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sample_stats[\"count\"].plot(ax = ax1)\n",
    "ax1.vlines(quant_threshold, ymin=sample_stats[\"count\"].min(), \n",
    "    ymax=sample_stats[\"count\"].max(), linestyle='dashed', color=\"firebrick\")\n",
    "ax1.set_title(\"Count\")\n",
    "\n",
    "sample_stats[\"min_fbeta\"].plot(ax = ax2)\n",
    "ax2.vlines(quant_threshold, ymin=sample_stats[\"min_fbeta\"].min(), \n",
    "    ymax=sample_stats[\"min_fbeta\"].max(), linestyle='dashed', color=\"firebrick\")\n",
    "ax2.set_title(\"Fbeta\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual: What do the distributions of alpha and lamda look like with that threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df['top'] = np.where(agg_df['fbeta']>=agg_df['fbeta'].quantile(quant_threshold/100),'top','low')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize separation by parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha by year\n",
    "\n",
    "ax = sns.relplot(x=\"alpha\",y=\"fbeta\", \n",
    "    col=\"start\",hue=\"top\",palette=\"rocket\",\n",
    "    data=agg_df,edgecolor=\"black\",linewidth=0.5,s=100)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lamda by year\n",
    "\n",
    "ax = sns.relplot(x=\"lamda\",y=\"fbeta\", \n",
    "    col=\"start\",hue=\"top\",palette=\"rocket\",\n",
    "    data=agg_df,edgecolor=\"black\",linewidth=0.5,s=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta by year\n",
    "\n",
    "ax = sns.relplot(x=\"beta\",y=\"fbeta\", \n",
    "    col=\"start\",hue=\"top\",palette=\"rocket\",\n",
    "    data=agg_df,edgecolor=\"black\",linewidth=0.5,s=100)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize overall parameter distributions of sampled sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top parameter distribution plot\n",
    "\n",
    "ax = sns.relplot(x=\"alpha\", y=\"lamda\", \n",
    "    col=\"start\", hue=\"fbeta\", palette=\"mako_r\", \n",
    "    data=agg_df.loc[agg_df['top']==\"top\"])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a multivariate normal distribution and sampled parameters\n",
    "Using the samples above your threshold, randomly sample a set of new parameter sets from their distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many distinct parameter samples do you want to generate?\n",
    "n_samples = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits a separate distribution per year \n",
    "\n",
    "samples_to_run = generate_param_samples(agg_df, n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sampled parameters to .csv as a backup/for later use\n",
    "\n",
    "samples_to_run.to_csv(f\"{stats_dir}/sampled_param_sets.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the parameter distributions that will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to visually examine the parameter posterior distributions\n",
    "\n",
    "ax = sns.jointplot(x=\"alpha\", y=\"lamda\", hue=\"start\", data=samples_to_run, palette=\"deep\", alpha = 0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model forecast\n",
    "\n",
    "First write out the commands with the new sampled parameter sets. One run will be conducted with each parameter sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_forecast = \"\"\n",
    "\n",
    "for index, row in samples_to_run.iterrows():\n",
    "    commands_forecast += write_commands(row, start_run = 0, end_run = 0, run_type = \"forecast\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If you will run on HPC or later, write these to file \n",
    "\n",
    "# f1 = open(stats_dir + \"/commands.txt\", 'w')\n",
    "# f1.write(commands_forecast)\n",
    "# f1.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to execute all model runs. These must complete before you can calculate \n",
    "the summary statistics. Remember that this may take some time (approximately 2 - 5 minutes \n",
    "per run per core, depending on your computer and number of time-steps in your simulation), \n",
    "so prepare accordingly!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model here\n",
    "for command in commands_forecast.split('\\n'):\n",
    "    ! {command}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These runs will write out to \"outputs/{run_name}_forecast/\". \n",
    "\n",
    "Calculate summary statistics on completed runs. This is also run in parallel, so time \n",
    "will vary depending on how many cores you use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary stats\n",
    "\n",
    "! python pandemic/get_stats.py forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review model summary statistics\n",
    "\n",
    "You can summarize the model runs now with a single set of summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"{sim_name}_forecast\"\n",
    "stats_dir = f\"{out_dir}/summary_stats/{run_name}\"\n",
    "\n",
    "agg_df = (\n",
    "    pd.read_csv(f\"{stats_dir}/summary_stats_bySample.csv\")\n",
    "    .rename(columns=col_dict)\n",
    "    )\n",
    "\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Final forecast summary results:\"\n",
    "    f\"F-beta = {agg_df.loc[0,'fbeta']}\"\n",
    "    f\"Probability of intro. to {coi} by {sim_years}: {agg_df.loc[0, [col for col in agg_df.columns if 'prob_by_' in col]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step: Visualize forecast\n",
    "\n",
    "Use notebook 4 to visualize the full results of your forecast simulation. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "948a6e006881c847639198d4e28507cd0955feff6e008072919ba7456f12f8bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('Pandemic': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
