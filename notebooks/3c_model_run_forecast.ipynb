{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model run: Forecast \n",
    "Use this notebook to run and evaluate a parameter grid-search. \n",
    "\n",
    "This notebook can be run after 0, 1, 2, and 3b. We recommend also running 3a first, to check for and troubleshoot issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dotenv\n",
    "import os \n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandemic.multirun_helpers.command_writer import write_commands\n",
    "# import summary stats run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables and paths from .env\n",
    "dotenv.load_dotenv('.env')\n",
    "\n",
    "# Read environmental variables\n",
    "input_dir = os.getenv('INPUT_PATH')\n",
    "out_dir = os.getenv('OUTPUT_PATH')\n",
    "path_to_config_json = os.getenv('CONFIG_PATH')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the summary stats from the grid search to fit distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_config_json) as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "sim_name = config['sim_name']\n",
    "add_descript = config[\"add_descript\"]\n",
    "\n",
    "run_name = f\"{sim_name}_{add_descript}_calibrate\"\n",
    "total_runs = config[\"run_count\"] \n",
    "\n",
    "run_name = \"slf_grid_agg\"\n",
    "\n",
    "stats_dir = f\"{out_dir}/summary_stats/{run_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {\"start_max\":\"start\",\"alpha_max\":\"alpha\",\"beta_max\":\"beta\",\n",
    "    \"lamda_max\":\"lamda\",\"count_known_countries_time_window_fbeta_mean\":\"fbeta\"}\n",
    "\n",
    "agg_df = (\n",
    "    pd.read_csv(f\"{stats_dir}/summary_stats_bySample.csv\")\n",
    "    .rename(columns=col_dict)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring possible quantile thresholds for fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold - adjust based on the below plots\n",
    "\n",
    "quant_threshold = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vals = []\n",
    "min_fbeta = []\n",
    "\n",
    "for val in range(70,100):\n",
    "    subset = agg_df.loc[agg_df['fbeta']>=agg_df['fbeta'].quantile(val/100)]\n",
    "    count_vals.append(len(subset.index))\n",
    "    min_fbeta.append(subset['fbeta'].min())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_stats = pd.DataFrame(\n",
    "    {\"quantile\":range(70,100), \n",
    "    \"count\":count_vals, \n",
    "    \"min_fbeta\":min_fbeta}\n",
    "    ).set_index(\"quantile\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual: How many samples and what Fbeta scores are captured with each threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sample_stats[\"count\"].plot(ax = ax1)\n",
    "ax1.vlines(quant_threshold, ymin=sample_stats[\"count\"].min(), ymax=sample_stats[\"count\"].max(), linestyle='dashed', color=\"firebrick\")\n",
    "ax1.set_title(\"Count\")\n",
    "\n",
    "sample_stats[\"min_fbeta\"].plot(ax = ax2)\n",
    "ax2.vlines(quant_threshold, ymin=sample_stats[\"min_fbeta\"].min(), ymax=sample_stats[\"min_fbeta\"].max(), linestyle='dashed', color=\"firebrick\")\n",
    "ax2.set_title(\"Fbeta\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual: What do the distributions of alpha and lamda look like with that threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df['top']=np.where(agg_df['fbeta']>=agg_df['fbeta'].quantile(quant_threshold/100),'top','low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((agg_df.loc[agg_df['top']==\"top\", \"alpha\"] + agg_df.loc[agg_df['top']==\"top\", \"lamda\"]).values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha by year\n",
    "\n",
    "ax = sns.relplot(x=\"alpha\",y=\"fbeta\", col=\"start\",hue=\"top\",palette=\"rocket\",data=agg_df,edgecolor=\"black\",linewidth=0.5,s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lamda by year\n",
    "\n",
    "ax = sns.relplot(x=\"lamda\",y=\"fbeta\", col=\"start\",hue=\"top\",palette=\"rocket\",data=agg_df,edgecolor=\"black\",linewidth=0.5,s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta by year\n",
    "\n",
    "ax = sns.relplot(x=\"beta\",y=\"fbeta\", col=\"start\",hue=\"top\",palette=\"rocket\",data=agg_df,edgecolor=\"black\",linewidth=0.5,s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top parameter distribution plot\n",
    "\n",
    "ax = sns.relplot(x=\"alpha\", y=\"lamda\", col=\"start\", hue=\"fbeta\", palette=\"mako_r\", data=agg_df.loc[agg_df['top']==\"top\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the multivariate normal distribution and sampled parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many distinct parameter samples do you want to generate?\n",
    "n_samples = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits a separate distribution per year \n",
    "\n",
    "start_years = agg_df.start.unique()\n",
    "param_samples_df = pd.DataFrame(columns=['alpha','beta','lamda','start'])\n",
    "\n",
    "top_sets=(\n",
    "    agg_df\n",
    "    .loc[(agg_df['top']==\"top\")]\n",
    "    [[\"start\",\"alpha\",\"beta\",\"lamda\",\"fbeta\"]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "top_count = len(top_sets.index)\n",
    "\n",
    "year_counts = []\n",
    "year_len = []\n",
    "\n",
    "for year in start_years:\n",
    "    year_sets= top_sets.loc[top_sets['start'] == year].reset_index(drop=True)\n",
    "    year_counts.append(int(len(year_sets.index)*n_samples/top_count))\n",
    "\n",
    "    param_mean = np.mean(top_sets[[\"alpha\",\"beta\",\"lamda\"]].values, axis=0)\n",
    "    param_cov = np.cov(top_sets[[\"alpha\",\"beta\",\"lamda\"]].values, rowvar=0)\n",
    "    param_sample = np.random.multivariate_normal(param_mean, param_cov, int(n_samples*1.1))\n",
    "    alpha = param_sample[:,0]\n",
    "    beta = param_sample[:,1]\n",
    "    lamda = param_sample[:,2]\n",
    "    start = [year]*int(n_samples*1.1)\n",
    "    param_sample_df = pd.DataFrame({\"alpha\":alpha, \"lamda\":lamda, \"beta\":beta,\"start\":start})\n",
    "    param_sample_df.loc[param_sample_df['alpha']<=1].reset_index(drop=True)\n",
    "\n",
    "    param_samples_df = pd.concat([param_samples_df, param_sample_df]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"Year: {year}, Means: {param_mean}, Covariance Matrix: {param_cov}\")\n",
    "\n",
    "samp_runs = [item for sublist in [list(range(i*int(n_samples*1.1), int(n_samples*1.1)*i + year_count)) for i, year_count in enumerate(year_counts)] for item in sublist]\n",
    "\n",
    "samples_to_run = param_samples_df.loc[samp_runs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sampled parameters to .csv as a backup/for later use\n",
    "\n",
    "samples_to_run.to_csv(f\"{stats_dir}/sampled_param_sets.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the parameter distributions that will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to visually examine - should show similar patterns to top parameter distribution plots above\n",
    "\n",
    "ax = sns.relplot(x=\"alpha\", y=\"lamda\", col=\"start\", data=samples_to_run, alpha = 0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to visually examine - should show similar patterns to top parameter distribution plot above\n",
    "\n",
    "ax = sns.jointplot(x=\"alpha\", y=\"lamda\", hue=\"start\", data=samples_to_run, palette=\"deep\", alpha = 0.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out sampled parameters to runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_forecast = \"\"\n",
    "\n",
    "for index, row in samples_to_run.iterrows():\n",
    "    commands_forecast += write_commands(row, start_run = 0, end_run = 0, run_type = \"forecast\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run forecast with sampled parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model here\n",
    "for command in commands_forecast.split('\\n'):\n",
    "    ! {command}\n",
    "\n",
    "# Write to outdir/run_name + _forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary stats\n",
    "\n",
    "# Update summary stats script:\n",
    "\n",
    "# If path ends in _forecast\n",
    "# Agg on run rather than sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review model summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step: Visualize forecast\n",
    "\n",
    "Use notebook 4 to visualize the results of your forecast simulation. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "948a6e006881c847639198d4e28507cd0955feff6e008072919ba7456f12f8bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('Pandemic': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
