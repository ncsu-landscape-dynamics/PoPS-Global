{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visuals to help in model calibration\n",
    "When using parameter grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_root = \"Q:\"\n",
    "data_path = r\"\\Shared drives\\Pandemic Data\"\n",
    "model_name = \"slf_model\"\n",
    "run_name = \"slf_grid_broad\"\n",
    "total_runs = 80 # Count of runs expected (this is only needed if you had variable #'s of runs - ie. from two rounds of parameter sampling)\n",
    "\n",
    "data_dir = f\"{google_root}{data_path}\\{model_name}\"\n",
    "\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dir = f\"{data_dir}/outputs/summary_stats/{run_name}\"\n",
    "# input_dir = \"inputs\"\n",
    "input_dir = f\"{data_dir}/inputs/noTWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv(\n",
    "        input_dir + \"/first_records_validation.csv\",\n",
    "        header=0,\n",
    "        index_col=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv(f\"{stats_dir}/summary_stats_wPrecisionRecallF1FBetaAggProb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed if you have variable numbers of runs (to get the set you are looking for...)\n",
    "\n",
    "stats = stats.groupby(\"sample\").filter(lambda x: len(x) == total_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    \"start\":[\"max\"],\n",
    "    \"alpha\":[\"max\"],\n",
    "    \"lamda\": [\"max\"],\n",
    "    \"count_known_countries_time_window_fbeta\": [\"mean\",\"std\"]\n",
    "}\n",
    "\n",
    "agg_dict = {**agg_dict}\n",
    "\n",
    "agg_df = stats.groupby(\"sample\").agg(agg_dict)\n",
    "\n",
    "agg_df.columns = [\"_\".join(x) for x in agg_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = agg_df.rename(columns={\"start_max\":\"start\",\"alpha_max\":\"alpha\",\"lamda_max\":\"lamda\",\"count_known_countries_time_window_fbeta_mean\":\"fbeta\"})\n",
    "agg_df['st_err']=agg_df['count_known_countries_time_window_fbeta_std']/np.sqrt(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df.reset_index(inplace=True)\n",
    "agg_df.sort_values('fbeta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing run convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 runs\n",
    "top20 = agg_df.sort_values('fbeta',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convergence of top 20 runs?\n",
    "samples = list(agg_df.sort_values('fbeta',ascending=False).head(20).reset_index()['sample'])\n",
    "runs = list(range(0,stats['run_num'].max()))\n",
    "\n",
    "samples_df = pd.DataFrame({'runs':runs})\n",
    "i=1\n",
    "for sample in samples:\n",
    "    sample_fbeta = []\n",
    "    stdev = []\n",
    "    sterr = []\n",
    "    for run in runs:\n",
    "        filtered_stats = stats.loc[(stats['run_num']<=run) & (stats['sample']==sample)]\n",
    "        value = filtered_stats[\"count_known_countries_time_window_fbeta\"].mean()\n",
    "        sdev = filtered_stats[\"count_known_countries_time_window_fbeta\"].std() # this gives the standard deviation of the sample - mean\n",
    "        sample_fbeta.append(value)\n",
    "        stdev.append(sdev)\n",
    "        sterr.append(np.std(sample_fbeta)) # this gives the standard error of the mean\n",
    "    samples_df[f\"sample {i}\"]=sample_fbeta\n",
    "    samples_df[f\"stdev {i}\"]=stdev\n",
    "    samples_df[f\"sterr {i}\"]=sterr\n",
    "    i += 1\n",
    "\n",
    "samples_df.set_index(\"runs\",inplace=True)    \n",
    "samples_df[\"all samples\"]=samples_df.mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "ax = samples_df.loc[:,'sample 1':'sample 20':3].plot(ylim=[0.6,0.7],color=['maroon',\n",
    " 'maroon',\n",
    " 'maroon',\n",
    " 'maroon',\n",
    " 'maroon',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey',\n",
    " 'darkslategrey'],ylabel=\"fbeta\",title=\"Mean fbeta convergence \\n for the top 20 parameter samples\",legend=False)\n",
    "# for i in range(1, len(samples)):\n",
    "#     ax.fill_between(samples_df.index, samples_df[f\"sample {i+1}\"]+samples_df[f\"sterr {i+1}\"], samples_df[f\"sample {i+1}\"]-samples_df[f\"sterr {i+1}\"],color='#366da0',alpha=0.15)\n",
    "ax.set_xlabel(\"# of Runs\",fontsize=16)\n",
    "ax.set_ylabel(\"Fbeta mean\",fontsize=16)\n",
    "ax.tick_params(labelsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing alpha/lamda/year value performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(font_scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.stripplot(x='alpha', y='fbeta', hue='start', palette='mako',linewidth=0.2, data=agg_df, jitter=0.4)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1],bbox_to_anchor=(1.25,1), loc='upper right', borderaxespad=0,title=\"start year\")\n",
    "ax.set(ylim=(0,1))\n",
    "ax.axes.set_title(\"Mean Sample Fbeta, by Alpha Value\\n (Color = Year)\",fontsize=16)\n",
    "ax.set_xlabel(\"Alpha\",fontsize=16)\n",
    "ax.set_ylabel(\"Fbeta mean\",fontsize=16)\n",
    "ax.tick_params(labelsize=13)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='lamda',y='fbeta',hue='start',data=agg_df,palette='mako',edgecolor=\"black\",linewidth=0.2,legend='full') \n",
    "ax.set(ylim=(0, 1))\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1],bbox_to_anchor=(1.25,1), loc='upper right', borderaxespad=0,title=\"start year\")\n",
    "ax.axes.set_title(\"Mean Sample Fbeta, by Lambda Value\\n (Color = Year)\",fontsize=16)\n",
    "ax.set_xlabel(\"Lambda\",fontsize=16)\n",
    "ax.set_ylabel(\"Fbeta mean\",fontsize=16)\n",
    "ax.tick_params(labelsize=13)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.stripplot(x='start', y='fbeta', hue='alpha', palette='mako',linewidth=0.2, data=agg_df, jitter=0.3)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1],bbox_to_anchor=(1.25,1), loc='upper right', borderaxespad=0,title=\"alpha\")\n",
    "ax.set(ylim=(0,1))\n",
    "ax.axes.set_title(\"Mean Sample Fbeta, by Start Year\\n (Color = Alpha)\",fontsize=16)\n",
    "ax.set_xlabel(\"Start year\",fontsize=16)\n",
    "ax.set_ylabel(\"Fbeta mean\",fontsize=16)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='15') # for legend text\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='15') # for legend title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animated visual of individual sample (multiple runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting individual run introductions to make the animated visual\n",
    "import geopandas\n",
    "\n",
    "results_dir = \"outputs/slf_start_year/year2005_alpha0.2_lamda3.15_6801-6804\"\n",
    "paths = Path(results_dir).glob('**/origin_destination.csv')\n",
    "\n",
    "countries_path = \"inputs/noTWN/countries_slf_hiiMask16.gpkg\"\n",
    "countries_geo = geopandas.read_file(countries_path)\n",
    "org_dest_all = pd.DataFrame()\n",
    "\n",
    "lat_lon = countries_geo[[\"NAME\",\"LON\",\"LAT\"]]\n",
    "paths = Path(results_dir).glob('**/origin_destination.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    path_in_str = str(path)\n",
    "    org_dest = (pd.read_csv(path)).iloc[:,1:4]\n",
    "    org_dest[\"TS\"] = org_dest[\"TS\"].astype(str)\n",
    "    org_dest_all = org_dest_all.append(org_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_lat_lon = lat_lon.rename(columns={'NAME':'Origin'})\n",
    "# org_dest_all.merge(lat_lon, how='left',on='Origin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_origins = org_dest_all.merge(origin_lat_lon, how='left',on='Origin')\n",
    "with_origins.rename(columns={'LAT':'LatOrigin','LON':'LonOrigin'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_lat_lon = lat_lon.rename(columns={'NAME':'Destination'})\n",
    "with_orig_dest = with_origins.merge(destination_lat_lon, how='left',on='Destination')\n",
    "with_orig_dest.rename(columns={'LAT':'LatDest','LON':'LonDest'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_orig_dest['date_time'] = pd.to_datetime(with_orig_dest['TS'],format=\"%Y%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_orig_dest['intros'] = with_orig_dest.groupby('Destination').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_orig_dest.to_csv('or_dest.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "948a6e006881c847639198d4e28507cd0955feff6e008072919ba7456f12f8bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('Pandemic': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
