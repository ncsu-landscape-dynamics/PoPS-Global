{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PoPS Global Model: Interactive test run\n",
    "## Predicting the spread of plant pests or pathogens using trade, environment, and pest ecology open data\n",
    "\n",
    "Notebooks 3a - 3c provide the workflow for running the PoPS Global Model. To run these notebooks, \n",
    "the following are assumed:\n",
    "- Cloned the Pandemic GitHub repository (git clone \n",
    "https://github.com/ncsu-landscape-dynamics/PoPS-Global.git)\n",
    "- Notebook launched from the notebook folder of the cloned repo\n",
    "- Already have created the environment file (see 0_create_env_file notebook), required data \n",
    "downloaded and formatted (see 1_data_acquisition_format notebook), and set up the model \n",
    "configurations (see 2_create_model_config notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import requisite python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the repository main directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant PoPS Global functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandemic.helpers import create_trades_list\n",
    "from pandemic.model_equations import pandemic_multiple_time_steps\n",
    "from pandemic.output_files import (\n",
    "    create_model_dirs,\n",
    "    save_model_output,\n",
    "    aggregate_monthly_output_to_annual,\n",
    "    write_model_metadata,\n",
    "    write_annual_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths and Environment Variables\n",
    "Read in variables from the .env file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables and paths from .env\n",
    "dotenv.load_dotenv(\".env\")\n",
    "\n",
    "# Read environmental variables\n",
    "input_dir = os.getenv(\"INPUT_PATH\")\n",
    "out_dir = os.getenv(\"OUTPUT_PATH\")\n",
    "countries_path = os.getenv(\"COUNTRIES_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test run the model in this notebook\n",
    "\n",
    "After configuring your model parameters in 2, you can run the model interactively in this notebook as a \n",
    "test run. This will still generate model outputs, one run at a time.\n",
    "\n",
    "Once you ensure that the model is functioning as expected (no errors due to missing input data, \n",
    "misformatted parameters, etc.), you can launch full calibration runs using grid search and the subsequent \n",
    "forecast using sampled parameters can from notebooks 3b and 3c. In these notebooks, multiple model runs \n",
    "are run in parallel and outputs are written directly to file. \n",
    "\n",
    "### Read in config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read model arguments from configuration file\n",
    "with open(\"config.json\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "sim_name = config[\"sim_name\"]\n",
    "\n",
    "commodity_path = config[\"commodity_path\"]\n",
    "commodity_forecast_path = config[\"commodity_forecast_path\"]\n",
    "commodity_list = config[\"commodity_list\"]\n",
    "native_countries_list = config[\"native_countries_list\"]\n",
    "season_dict = config[\"season_dict\"]\n",
    "alpha = config[\"alpha\"]\n",
    "beta = config[\"beta\"]\n",
    "mu = config[\"mu\"]\n",
    "lamda_c_list = config[\"lamda_c_list\"]\n",
    "phi = config[\"phi\"]\n",
    "w_phi = config[\"w_phi\"]\n",
    "start_year = config[\"start_year\"]\n",
    "stop_year = config[\"stop_year\"]\n",
    "random_seed = config[\"random_seed\"]\n",
    "# cols_to_drop = config[\"columns_to_drop\"] # Not sure where and how this gets defined\n",
    "time_infect_units = config[\"transmission_lag_unit\"]\n",
    "transmission_lag_type = config[\"transmission_lag_type\"]\n",
    "time_infect = config[\"time_to_infectivity\"]\n",
    "gamma_shape = config[\"transmission_lag_shape\"]\n",
    "gamma_scale = config[\"transmission_lag_scale\"]\n",
    "save_entry = config[\"save_entry\"]\n",
    "save_estab = config[\"save_estab\"]\n",
    "save_intro = config[\"save_intro\"]\n",
    "save_country_intros = config[\"save_country_intros\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Input Data\n",
    "\n",
    "Open the countries, distance, and climate similarity files created during data acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read formatted countries geopackage, distance matrix, and climate similarities matrix\n",
    "countries = geopandas.read_file(countries_path, driver=\"GPKG\")\n",
    "distances = np.load(input_dir + \"/distance_matrix.npy\")\n",
    "climate_similarities = np.load(input_dir + \"/climate_similarities_hiiMask16.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format trade data using the `create_trades_list` model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read & format trade data\n",
    "trades_list, file_list_filtered, code_list, commodities_available = create_trades_list(\n",
    "    commodity_path=commodity_path,\n",
    "    commodity_forecast_path=commodity_forecast_path,\n",
    "    commodity_list=commodity_list,\n",
    "    start_year=start_year,\n",
    "    stop_year=stop_year,\n",
    "    distances=distances,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dimensions of the trade data for the simulation from the trade files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of unique dates from trade data\n",
    "date_list = []\n",
    "for f in file_list_filtered:\n",
    "    fn = os.path.split(f)[1]\n",
    "    ts = str.split(os.path.splitext(fn)[0], \"_\")[-1]\n",
    "    date_list.append(ts)\n",
    "date_list.sort()\n",
    "end_sim_year = date_list[-1][:4]\n",
    "\n",
    "# Example trade array for formatting outputs\n",
    "traded = pd.read_csv(\n",
    "    file_list_filtered[0], sep=\",\", header=0, index_col=0, encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "# Checking trade array shapes\n",
    "print(\"Length of trades list: \", len(trades_list))\n",
    "for i in range(len(trades_list)):\n",
    "    print(\"\\tcommodity array shape: \", trades_list[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model \n",
    "\n",
    "After running the above cells to import data, the following cell runs the model.\n",
    "\n",
    "To generate multiple stochastic runs of the same model configuration with test_run, re-run just this cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of commodities: \", len([c for c in lamda_c_list if c > 0]))\n",
    "print(\"Number of time steps: \", trades_list[0].shape[0])\n",
    "for i in range(len(trades_list)):\n",
    "    if len(trades_list) > 1:\n",
    "        code = code_list[i]\n",
    "        print(\"\\nRunning model for commodity: \", code)\n",
    "    else:\n",
    "        code = code_list[0]\n",
    "        print(\n",
    "            \"\\nRunning model for commodity: \",\n",
    "            os.path.basename(commodities_available[0]),\n",
    "        )\n",
    "    trades = trades_list[i]\n",
    "    distances = distances\n",
    "    locations = countries\n",
    "    prob = np.zeros(len(countries.index))\n",
    "    pres_ts0 = [False] * len(prob)\n",
    "    infect_ts0 = np.empty(locations.shape[0], dtype=\"object\")\n",
    "    for country in native_countries_list:\n",
    "        country_index = countries.index[countries[\"ISO3\"] == country][0]\n",
    "        pres_ts0[country_index] = True\n",
    "        # if time steps are monthly and time to infectivity is in years\n",
    "        if len(date_list[0]) > 4:\n",
    "            infect_ts0[country_index] = str(start_year) + \"01\"\n",
    "        # else if time steps are annual and time to infectivity is in years\n",
    "        else:\n",
    "            infect_ts0[country_index] = str(start_year)\n",
    "    locations[\"Presence\"] = pres_ts0\n",
    "    locations[\"Infective\"] = infect_ts0\n",
    "\n",
    "    sigma_h = (1 - countries[\"Host Percent Area\"]).std()\n",
    "\n",
    "    if len(climate_similarities.shape) == 1:\n",
    "        sigma_kappa = np.std(1 - climate_similarities)\n",
    "    else:\n",
    "        iu1 = np.triu_indices(climate_similarities.shape[0], 1)\n",
    "        sigma_kappa = np.std(1 - climate_similarities[iu1])\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    lamda_c = lamda_c_list[i]\n",
    "\n",
    "    if lamda_c > 0:\n",
    "        e = pandemic_multiple_time_steps(\n",
    "            trades=trades,\n",
    "            distances=distances,\n",
    "            locations=locations,\n",
    "            climate_similarities=climate_similarities,\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            mu=mu,\n",
    "            lamda_c=lamda_c,\n",
    "            phi=phi,\n",
    "            sigma_h=sigma_h,\n",
    "            sigma_kappa=sigma_kappa,\n",
    "            w_phi=w_phi,\n",
    "            start_year=start_year,\n",
    "            date_list=date_list,\n",
    "            season_dict=season_dict,\n",
    "            transmission_lag_type=transmission_lag_type,\n",
    "            # time_infect_units=time_infect_units,\n",
    "            time_infect=time_infect,\n",
    "            gamma_shape=gamma_shape,\n",
    "            gamma_scale=gamma_scale,\n",
    "            # scenario_list=scenario_list\n",
    "        )\n",
    "\n",
    "        run_prefix = f\"{sim_name}_{code}\"\n",
    "\n",
    "        try:\n",
    "            run_num = (\n",
    "                int(\n",
    "                    os.path.basename(\n",
    "                        os.path.normpath(\n",
    "                            glob.glob(f\"{out_dir}/{sim_name}/{run_prefix}/run*/\")[0]\n",
    "                        )\n",
    "                    ).split(\"_\")[1]\n",
    "                )\n",
    "                + 1\n",
    "            )\n",
    "        except IndexError:\n",
    "            run_num = 0\n",
    "\n",
    "        print(f\"Starting run {run_num}...\")\n",
    "\n",
    "        arr_dict = {\n",
    "            \"prob_entry\": \"probability_of_entry\",\n",
    "            \"prob_intro\": \"probability_of_introduction\",\n",
    "            \"prob_est\": \"probability_of_establishment\",\n",
    "            \"country_introduction\": \"country_introduction\",\n",
    "        }\n",
    "\n",
    "        outpath = out_dir + f\"/{sim_name}/{run_prefix}/run_{run_num}/\"\n",
    "        create_model_dirs(\n",
    "            outpath=outpath,\n",
    "            output_dict=arr_dict,\n",
    "            write_entry_probs=save_entry,\n",
    "            write_estab_probs=save_estab,\n",
    "            write_intro_probs=save_intro,\n",
    "            write_country_intros=save_country_intros,\n",
    "        )\n",
    "        print(\"saving model outputs: \", outpath)\n",
    "        full_out_df = save_model_output(\n",
    "            model_output_object=e,\n",
    "            example_trade_matrix=traded,\n",
    "            outpath=outpath,\n",
    "            date_list=date_list,\n",
    "            write_entry_probs=save_entry,\n",
    "            write_estab_probs=save_estab,\n",
    "            write_intro_probs=save_intro,\n",
    "            write_country_intros=save_country_intros,\n",
    "            columns_to_drop=None,\n",
    "        )\n",
    "\n",
    "        # If time steps are monthly, aggregate predictions to\n",
    "        # annual for dashboard display\n",
    "        if len(date_list[i]) > 4:\n",
    "            print(\"aggregating monthly predictions to annual time steps...\")\n",
    "            aggregate_monthly_output_to_annual(\n",
    "                formatted_geojson=full_out_df, outpath=outpath\n",
    "            )\n",
    "\n",
    "        # If time steps are annual, export the predictions\n",
    "        if len(date_list[i]) == 4:\n",
    "            print(\"exporting annual predictions...\")\n",
    "            write_annual_output(formatted_geojson=full_out_df, outpath=outpath)\n",
    "\n",
    "        # Save model metadata to text file\n",
    "        print(\"writing model metadata...\")\n",
    "        write_model_metadata(\n",
    "            main_model_output=e[0],\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "            mu=mu,\n",
    "            lamda_c_list=lamda_c_list,\n",
    "            phi=phi,\n",
    "            sigma_h=sigma_h,\n",
    "            sigma_kappa=sigma_kappa,\n",
    "            w_phi=w_phi,\n",
    "            start_year=start_year,\n",
    "            end_sim_year=end_sim_year,\n",
    "            transmission_lag_type=transmission_lag_type,\n",
    "            time_infect_units=time_infect_units,\n",
    "            gamma_shape=gamma_shape,\n",
    "            gamma_scale=gamma_scale,\n",
    "            random_seed=random_seed,\n",
    "            time_infect=time_infect,\n",
    "            native_countries_list=native_countries_list,\n",
    "            countries_path=countries_path,\n",
    "            commodities_available=commodities_available[i],\n",
    "            commodity_forecast_path=commodity_forecast_path,\n",
    "            phyto_weights=list(locations[\"Phytosanitary Capacity\"].unique()),\n",
    "            outpath=outpath,\n",
    "            run_num=run_num,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        print(\"\\tskipping as pest is not transported with this commodity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: Calibration (Notebook 3b)\n",
    "\n",
    "After you've ensured that the model runs with no errors and the outputs are what you would expect, \n",
    "continue to notebook 3b to run and evaluate a full parameter grid search to calibrate the model."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "595f0950b0e640b7cc44dcd5d8e4045d59c1baaa1bb917ee0093ba5fe5fcdbda"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Pandemic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
